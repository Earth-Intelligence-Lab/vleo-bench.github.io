<!DOCTYPE html>
<html>
<head>
  <title>VLEO-Bench</title>
    <style>
        .hidden {
            display: none;
        }
    </style>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://kit.fontawesome.com/f8ddf9854a.js" crossorigin="anonymous"></script>
  <meta charset="utf-8">
  <meta name="description"
        content="A Comprehensive Benchmark of Vision-Language Models for Earth Oobservation (EO) Data">
  <meta name="keywords" content="VLEO-Bench, VLM, VLM Evaluation, Vision Language Model, Large Language Model, Large Multimodal Model, artificial intelligence, AI, AGI, artificial general intelligence, Remote Sensing, Earth Observation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> VLEO-Bench: A Comprehensive Benchmark of Vision-Language Models for Earth Oobservation (EO) Data</title>

  <link rel="icon" href="./static/images/vleo-icon.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/question_card.js"></script>
  <script src="./data/results/data_setting.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>
  <script src="./visualizer/data/data_public.js" defer></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <img src="static/images/vleo-icon.png" style="width:1em;vertical-align: middle" alt="Logo"/> 
            <span class="VLEO-Bench" style="vertical-align: middle">VLEO-Bench</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            A Comprehensive Benchmark of Vision-Language Models for Earth Oobservation (EO) Data
          </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=UYxdrBsAAAAJ&hl=en" style="text-decoration: none; color: inherit;">Chenhui Zhang<sup style="color:#6fbf73;">‚Ä†,1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://sherriewang.github.io/" style="text-decoration: none; color: inherit;">Sherrie Wang<sup style="color:#6fbf73;">1</sup></a>
              ,
            </span>
          
          </div>
          
          <br>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>Institute for Data, Systems, and Society, Massachusetts Institute of Technology</span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">‚Ä†Corresponding to:</span>
            <span class="author-block"><a href="chenhui5@mit.edu">chenhui5@mit.edu</a></span>
          </div>
          

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org/abs/2401.17600"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/papers/2401.17600"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <p style="font-size:18px">ü§ó</p>
                  </span>
                  <span>HF Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/collections/mit-ei/vleo-benchmark-datasets-65b789b0466555489cce0d70"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ü§ó</p>
                      <!-- üîó -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/Earth-Intelligence-Lab/vleo-bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="#leaderboard"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-trophy"></i>
                      <!-- <p style="font-size:18px">üèÜ</p> -->
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>

              
              <!-- Visualization Link. -->

              <!-- Twitter Link. -->
              <!-- <span class="link-block">
                <a href="https://twitter.com/danielz233/status/xxx"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-brands fa-x-twitter"></i>
                  </span>
                  <span>Twitter</span>
                </a>
              </span>

              <span class="link-block">
                <a href="#examples"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon has-text-white">
                    <i class="fa-solid fa-book"></i>
                  </span>
                  <span>Examples</span>
                </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<style>
  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 80%;
  }
  </style>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <!-- <div class="hero-body">
      <img src="static/images/tease_scores.png" alt="Examples from the dataset"/>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div> -->
      <!-- <div class="box m-5"> -->
        <div class="content has-text-centered">
          <img src="static/images/teaser_horizontal.svg" alt="Overview of VLEO-Bench"/>
          <p> Overview of the VLEO-Bench dataset. VLEO-Bench presents 11 challenging scenarios motivated by real-world applications of Earth Observation (EO) data. We aim to test the scene understanding, localization, counting, and change detection abilities of state-of-the-art instruction-following VLMs. </p>
        </div>
      <!-- </div> -->
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üîîNews</h2>
        <div class="content has-text-justified">
          <p>
              <b>üî•[2024-01-22]: Initial release of our benchmark!</b>
          </p>
      </div>      
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Large Vision-Language Models (VLMs) have demonstrated impressive performance on complex tasks involving visual input with natural language instructions. However, it remains unclear to what extent capabilities on natural images transfer to Earth observation (EO) data, which are predominantly satellite and aerial images less common in VLM training data. In this work, we propose a comprehensive benchmark to gauge the progress of VLMs toward being useful tools for EO data by assessing their abilities on scene understanding, localization and counting, and change detection tasks. Motivated by real-world applications, our benchmark includes scenarios like urban monitoring, disaster relief, land use, and conservation. We discover that, although state-of-the-art VLMs like GPT-4V possess extensive world knowledge that leads to strong performance on open-ended tasks like location understanding and image captioning, their poor spatial reasoning limits usefulness on object localization and counting tasks.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<!-- DATASET SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 VLEO-Bench">
    <img src="static/images/vleo-icon.png" style="width:1em;vertical-align: middle" alt="Logo"/>
    <span class="VLEO-Bench" style="vertical-align: middle">VLEO-Bench</span>
  </h1>
  </div>
</section>

<!-- <section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p> -->
            
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            In this paper, we provide an application-focused evaluation of instruction-following VLMs like GPT-4V for different capabilities in EO, including location understanding, zero-shot remote sensing scene understanding, world knowledge, text-grounded object localization and counting, and change detection. These capabilities provide the EO community with pathways for impact in real-world application areas, including urban monitoring, disaster relief, land use, and conservation.
          </p>
          <img src="static/images/teaser_vertical.svg" alt="algebraic reasoning" class="center">
          <br>
          <p><strong>Desired Capabilities for EO Data.</strong> To build an EO benchmark for VLMs, we focus on three broad categories of capabilities in our initial release: scene understanding, localization and counting, and change detection. Within each category, we construct evaluations based on applications ranging from animal conservation to urban monitoring. Our goals are to (1) evaluate the performance of existing VLMs, (2) provide insights into prompting techniques suitable for repurposing existing VLMs to EO tasks, and (3) implement an interface of data and models for flexible benchmark updates and evaluations of future VLMs. Our categories and tasks are:</p>

          <ul>
              <li><em>Scene Understanding</em>: To evaluate how VLMs combine high-level information extracted from images with latent knowledge learned through language modeling, we construct three datasets: 
                  <ol>
                      <li>a new <span style="background-color:#cfe2f3;">aerial landmark recognition</span> dataset to test the model's ability to recognize and geolocate landmarks in the United States;</li>
                      <li>the <span style="background-color:#cfe2f3;">RSICD</span> dataset to evaluate the model's ability to generate open-ended captions for Google Earth images;</li>
                      <li>the <span style="background-color:#cfe2f3;">BigEarthNet</span> dataset to probe the model's ability to identify land cover types in medium-resolution satellite images, and</li>
                      <li>the <span style="background-color:#cfe2f3;">fMoW-WILDS</span> and <span style="background-color:#cfe2f3;">PatternNet</span> datasets to assess the model's ability to classify land use in high-resolution satellite images.</li>
                  </ol>
              </li>
              <li><em>Localization &amp; Counting</em>: To evaluate whether VLMs can extract fine-grained information about a specific object and understand its spatial relationship to other objects, we assemble three datasets: 
                  <ol>
                      <li>the <span style="background-color:#cfe2f3;">DIOR-RSVG</span> dataset to assess Referring Expression Comprehension (REC) abilities, in which the model is required to localize objects based on their natural language descriptions;</li>
                      <li>the <span style="background-color:#cfe2f3;">NEON-Tree</span>, <span style="background-color:#cfe2f3;">COWC</span>, and <span style="background-color:#cfe2f3;">xBD</span> datasets to assess counting small objects like cluttered trees, cars, and buildings in aerial and satellite images;</li>
                      <li>the <span style="background-color:#cfe2f3;">aerial animal detection</span> dataset to gauge counting animal populations from tilted aerial images taken by handheld cameras.</li>
                  </ol>
              </li>
              <li><em>Change Detection</em>: To evaluate if VLMs can identify differences between multiple images and complete user-specified tasks based on such differences, we repurpose the <span style="background-color:#cfe2f3;">xBD</span> dataset. We show the model two high-resolution images taken before and after a natural disaster and ask it to assign damaged buildings to qualitative descriptions of damage categories.</li>
          </ul>

          <p>We note that a number of capabilities desired for EO data remain unattainable by current-generation VLMs due to their inability to ingest multi-spectral, non-optical, or multi-temporal images. This is unlikely to be addressed by the vision community while its focus remains on natural images. Furthermore, available VLMs do not yet perform image segmentation, although we expect this to change in the near future.</p>


        </div>
    </div>
    </div>

    <div class="content has-text-centered">
      <img src="static/images/strength_weakness.svg" alt="Strength and weakness of GPT-4V"/>
      <p> GPT-4V has scene understanding abilities but cannot accurately count or localize objects. We only select part of the user prompt and model response for illustration purposes. </p>
    </div>

    </div>

    <!-- <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Statistics</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/VLEO-xx.Jpeg" alt="algebraic reasoning" width="95%"/>
              <p> Statistics Figure 1.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/xx.Jpeg" alt="arithmetic reasoning" width="40%"/>
              <p> Statistics Figure 2</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/xx.png" alt="arithmetic reasoning" width="80%"/>
              <p> Statistics Figure 3</p>
            </div>
          </div>
        </div>
      </div>
    </div> -->
    <!-- <div class="columns is-centered m-6">
      <div class="column is-max-desktop has-text-centered">
        <h2 class="title is-3" id="visualization">Visualization</h2>
        <iframe src="visualizer/explore.html" style="width: 100%;min-height: 100vh; border-radius: 20px;"></iframe>
      </div>
    </div> -->
  </div>
</section>

<!-- RESULTS SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 VLEO-Bench">Experiment Results</h1>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Result Overview</h2>
        <div class="content has-text-justified">
          <p>Below, we summarize insights from our evaluations, with a focus on GPT-4V, as it is generally the best-performing VLM across Earth observation tasks. We elaborate on the results in Sections Scene Understanding, Localization &amp; Counting, and Change Detection.</p>

          <ul>
              <li><i>Scene Understanding</i>: 
                  <ol style="margin-left: 2.5em; padding-top: 1pt; list-style-type: none;">
                      <li>On our new <span style="background-color: #cfe2f3;">aerial landmark recognition</span> task, GPT-4V achieves an overall accuracy of 0.67, surpassing open models by a large margin and demonstrating its comprehensive world knowledge. There appear to be regional disparities, with GPT-4V generally performing better in coastal states. In addition, although GPT-4V sometimes generates sophisticated reasoning paths, the reasoning can be incorrect despite a correct final answer.</li>
                      <li>On <span style="background-color: #cfe2f3;">RSICD image captioning</span>, GPT-4V achieves a RefCLIPScore of 0.75, which measures both image-text semantic similarity and caption-reference similarity. Although GPT-4V does not achieve high similarity between generated and reference captions, our qualitative assessment is that it generates even more detailed captions than the humans employed in RSICD.</li>
                      <li>On land cover/land use classification tasks, GPT-4V performance varies depending on image resolution, label ambiguity, and label granularity. On <span style="background-color: #cfe2f3;">fMoW-WILDS</span>, the average F1-score is 0.19; on <span style="background-color: #cfe2f3;">PatternNet</span>, average F1-score is 0.71, and on <span style="background-color: #cfe2f3;">BigEarthNet</span>, average F1-score is 0.38. High performance on PatternNet can be attributed to high image resolution and disambiguated labels. Low performance on fMoW-WILDS is largely due to ambiguous labels, which we discuss in Section Land Cover/Land Use Classification.</li>
                  </ol>
              </li>

              <li><i>Localization &amp; Counting</i>: 
                  <ol style="margin-left: 2.5em; padding-top: 1pt; list-style-type: none;">
                      <li>On <span style="background-color: #cfe2f3;">DIOR-RSVG</span> object localization, GPT-4V obtains a mean intersection-over-union (IoU) of 0.16; only 7.6% of the test images have an IoU > 0.5, while a model that specializes in outputting bounding boxes achieves a mean IoU of 0.68.</li>
                      <li>While GPT-4V achieves moderate accuracies on the <span style="background-color: #cfe2f3;">COWC</span> vehicle counting and <span style="background-color: #cfe2f3;">xBD</span> building counting tasks, it fails on <span style="background-color: #cfe2f3;">NEON-Tree</span> counting and <span style="background-color: #cfe2f3;">aerial animal detection</span>.</li>
                  </ol>
              </li>

              <li><i>Change Detection</i>: On <span style="background-color: #cfe2f3;">xBD</span> change detection, GPT-4V fails to count and categorize the damaged buildings, with a performance score for buildings in the "destroyed" category. Although GPT-4V can count the number of buildings before a disaster with moderate accuracy, it systematically fails to assess the building damage by contrasting before and after images. This systematic failure makes it unusable for disaster relief applications that require counting abilities.</li>
          </ul>
      </div>
    </div>
    </div>
    </div>

    
  </div>
</section>
      



<!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content"> Incoming </div>
      </div>
    </div>
<!-------------------------------------------------------------------- Image Type SECTION -------------------------------------------------------------------->



<!-- @PAN TODO: bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
      @article{zhang2024vleobench,
        title   = {Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data},
        author  = {Chenhui Zhang and Sherrie Wang},
        year    = {2024},
        journal = {arXiv preprint arXiv: 2401.17600}
      }
</code></pre>
  </div>
</section>

<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://mathvista.github.io/">MathVista</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->

</footer>

<script>
  function changeButtonText() {
    var button = document.getElementById('toggleButton');
    if (button.innerHTML.includes("Test Set Leaderboard")) {
      button.innerHTML = "<b style='font-size: larger;'>Validation Set Leaderboard</b> (Click to Switch)";
    } else {
      button.innerHTML = "<b style='font-size: larger;'>Test Set Leaderboard</b> (Click to Switch)";
    }
  }
  document.addEventListener('DOMContentLoaded', function() {
    var tables = document.querySelectorAll('table');
    
    tables.forEach(function(table) {
        if (!table) return;

        var initialRows = Array.from(table.rows).slice(1);
        table.addEventListener('click', function(event) {
            var clickedCell = event.target.closest('td, th');
            if (!clickedCell) return;
            var headerRow = clickedCell.parentNode;
            var columnIndex = Array.from(headerRow.cells).indexOf(clickedCell);
            var type = clickedCell.getAttribute('data-type');

            if (headerRow.rowIndex === 0) {
                if (columnIndex === 0) {
                    table.tBodies[0].innerHTML = '';
                    initialRows.forEach(row => table.tBodies[0].appendChild(row.cloneNode(true)));
                }
            }
        });
    });
});

function sortTable(table, column, type, asc) {
    var tbody = table.tBodies[0];
    var rows = Array.from(tbody.rows);

    rows.sort(function(a, b) {
        var valA = a.cells[column].textContent;
        var valB = b.cells[column].textContent;

        if (type === 'number') {
            valA = parseFloat(valA);
            valB = parseFloat(valB);
        }

        return asc ? valA - valB : valB - valA;
    });

    rows.forEach(row => tbody.appendChild(row));
}

  // ÂàáÊç¢Ë°®Ê†ºÁöÑÂáΩÊï∞
  function toggleTables () {
      var table1 = document.getElementById('table1');
      var table2 = document.getElementById('table2');
      table1.classList.toggle('hidden');
      table2.classList.toggle('hidden');
  }

  document.getElementById('toggleButton').addEventListener('click', toggleTables);
  const canvas = document.getElementById('difficulty_level_chart');
  canvas.style.width = '500px';
  canvas.style.height = '120px';
  const ctx = document.getElementById('difficulty_level_chart').getContext('2d');
  const difficulty_level_chart = new Chart(ctx, {
    type: 'bar',
    data: {
      labels: ['Easy', 'Medium', 'Hard', 'Overall'],
      datasets: [{
        label: 'Fuyu-8B',
        data: [28.9, 27, 26.4, 27.4],
        backgroundColor: 'rgba(196, 123, 160, 0.6)',
        borderColor: 'rgba(196, 123, 160, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(196, 123, 160, 1)'
      },
      {
        label: 'Qwen-VL-7B',
        data: [39.4, 31.9, 27.6, 32.9],
        backgroundColor: 'rgba(245, 123, 113, 0.6)',
        borderColor: 'rgba(245, 123, 113, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(245, 123, 113, 1)'
      },
      {
        label: 'LLaVA-1.5-13B',
        data: [41.3, 32.7, 26.7, 33.6],
        backgroundColor: 'rgba(255, 208, 80, 0.6)',
        borderColor: 'rgba(255, 208, 80, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 208, 80, 1)'
      },
      {
        label: 'InstructBLIP-T5-XXL',
        data: [40.3, 32.3, 29.4, 33.8],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      },
      {
        label: 'BLIP-2 FLAN-T5-XXL',
        data: [41, 32.7, 28.5, 34],
        backgroundColor: 'rgba(255, 153, 78, 0.6)',
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'GPT-4V',
        data: [76.1, 55.6, 31.2, 55.7],
        backgroundColor: 'rgba(117, 209, 215, 0.6)',
        borderColor: 'rgba(117, 209, 215, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(117, 209, 215, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,     
        max: 100,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 // ËÆæÁΩÆXËΩ¥Â≠ó‰ΩìÂ§ßÂ∞è
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 // ËÆæÁΩÆÊ†áÁ≠æÊñáÂ≠óÂ§ßÂ∞è
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });
  document.addEventListener('DOMContentLoaded', function() {
    // Data for the "Diagrams" chart
    const data_Diagrams = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.6, 30.1, 31.8, 30.0, 32.0, 46.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };

    // "data_Diagrams" chart
    new Chart(document.getElementById('chart_Diagrams'), {
        type: 'bar',
        data: data_Diagrams,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Tables" chart
    const data_Tables  = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [26.6, 29.0, 29.8, 27.8, 27.8, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Tables'), {
        type: 'bar',
        data: data_Tables,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_PlotsAndCharts " chart
    const data_PlotsAndCharts   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [24.8, 31.8, 36.2, 30.4, 35.8, 55.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PlotsAndCharts'), {
        type: 'bar',
        data: data_PlotsAndCharts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_ChemicalStructures " chart
    const data_ChemicalStructures   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [25.0, 27.2, 27.1, 26.7, 25.5, 50.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ChemicalStructures'), {
        type: 'bar',
        data: data_ChemicalStructures ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Photographs " chart
    const data_Photographs   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.6, 40.5, 41.4, 44.4, 42.0, 64.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Photographs'), {
        type: 'bar',
        data: data_Photographs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Paintings " chart
    const data_Paintings   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [28.7, 57.2, 53.6, 56.3, 52.1, 75.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Paintings'), {
        type: 'bar',
        data: data_Paintings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_GeometricShapes " chart
    const data_GeometricShapes   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.1, 25.3, 21.4, 25.6, 28.3, 40.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_GeometricShapes'), {
        type: 'bar',
        data: data_GeometricShapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_SheetMusic " chart
    const data_SheetMusic   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [35.2, 33.4, 34.6, 35.8, 34.9, 38.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SheetMusic'), {
        type: 'bar',
        data: data_SheetMusic ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_MedicalImages " chart
    const data_MedicalImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [25.4, 29.8, 31.6, 36.4, 29.8, 59.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MedicalImages'), {
        type: 'bar',
        data: data_MedicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_PathologicalImages " chart
    const data_PathologicalImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [26.5, 27.7, 31.2, 35.2, 35.6, 63.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PathologicalImages'), {
        type: 'bar',
        data: data_PathologicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_MicroscopicImages " chart
    const data_MicroscopicImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.0, 37.6, 29.2, 36.3, 32.7, 58.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MicroscopicImages'), {
        type: 'bar',
        data: data_MicroscopicImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_MRIsCTScansXrays " chart
    const data_MRIsCTScansXrays   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.7, 36.9, 33.3, 39.4, 29.8, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MRIsCTScansXrays'), {
        type: 'bar',
        data: data_MRIsCTScansXrays ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_SketchesAndDrafts " chart
    const data_SketchesAndDrafts   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [37.0, 32.1, 29.9, 38.0, 33.7, 55.4],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SketchesAndDrafts'), {
        type: 'bar',
        data: data_SketchesAndDrafts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Maps " chart
    const data_Maps   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.2, 36.5, 45.9, 47.6, 43.5, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Maps'), {
        type: 'bar',
        data: data_Maps ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_TechnicalBlueprints " chart
    const data_TechnicalBlueprints   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [24.7, 25.9, 28.4, 25.3, 27.8, 38.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TechnicalBlueprints'), {
        type: 'bar',
        data: data_TechnicalBlueprints ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_TreesAndGraphs " chart
    const data_TreesAndGraphs   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.1, 28.1, 28.8, 28.8, 34.9, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TreesAndGraphs'), {
        type: 'bar',
        data: data_TreesAndGraphs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_MathematicalNotations " chart
    const data_MathematicalNotations   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [15.8, 27.1, 22.6, 21.8, 21.1, 45.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MathematicalNotations'), {
        type: 'bar',
        data: data_MathematicalNotations ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_ComicsAndCartoons " chart
    const data_ComicsAndCartoons   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [29.0, 51.9, 49.6, 54.2, 51.1, 68.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ComicsAndCartoons'), {
        type: 'bar',
        data: data_ComicsAndCartoons ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Sculpture " chart
    const data_Sculpture   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.8, 46.2, 49.6, 51.3, 53.0, 76.1],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Sculpture'), {
        type: 'bar',
        data: data_Sculpture ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Portraits " chart
    const data_Portraits   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [20.9, 52.7, 46.2, 54.9, 47.3, 70.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Portraits'), {
        type: 'bar',
        data: data_Portraits ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Screenshots " chart
    const data_Screenshots   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.6, 35.7, 38.6, 34.3, 47.1, 65.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Screenshots'), {
        type: 'bar',
        data: data_Screenshots ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Other " chart
    const data_Other   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [28.3, 38.3, 50.0, 51.7, 58.3, 68.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Other'), {
        type: 'bar',
        data: data_Other ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Poster " chart
    const data_Poster   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.6, 50.9, 52.6, 61.4, 64.9, 80.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Poster'), {
        type: 'bar',
        data: data_Poster ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_IconsAndSymbols " chart
    const data_IconsAndSymbols   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [23.8, 66.7, 57.1, 59.5, 59.5, 78.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_IconsAndSymbols'), {
        type: 'bar',
        data: data_IconsAndSymbols ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_HistoricalTimelines " chart
    const data_HistoricalTimelines   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.0, 36.7, 40.0, 43.3, 43.3, 63.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_HistoricalTimelines'), {
        type: 'bar',
        data: data_HistoricalTimelines ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_3DRenderings " chart
    const data_3DRenderings   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [33.3, 28.6, 57.1, 38.1, 47.6, 47.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_3DRenderings'), {
        type: 'bar',
        data: data_3DRenderings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_DNASequences " chart
    const data_DNASequences   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [20.0, 45.0, 25.0, 25.0, 45.0, 55.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_DNASequences'), {
        type: 'bar',
        data: data_DNASequences ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Landscapes " chart
    const data_Landscapes   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [43.8, 43.8, 50.0, 31.2, 62.5, 68.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Landscapes'), {
        type: 'bar',
        data: data_Landscapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_LogosAndBranding " chart
    const data_LogosAndBranding   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.4, 57.1, 64.3, 35.7, 50.0, 85.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_LogosAndBranding'), {
        type: 'bar',
        data: data_LogosAndBranding ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Advertisements " chart
    const data_Advertisements   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.0, 60.0, 50.0, 60.0, 70.0, 100.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Advertisements'), {
        type: 'bar',
        data: data_Advertisements ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
});

</script>

<style>
  svg {
    height: 20px;
  }
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' ‚Üë';
  }
  .desc::after {
      content: ' ‚Üì';
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* Èº†Ê†áÊÇ¨ÂÅúÊó∂ÁöÑÈò¥ÂΩ±ÊïàÊûú */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>

</body>
</html>
